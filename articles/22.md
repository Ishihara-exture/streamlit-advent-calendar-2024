# 22日目
こんにちは。22日目担当の[こみぃ](https://x.com/kommy_jp)です。

21日目に作った素敵なチャットアプリですが、今の状態だと単発の質問に回答をもらう形です。  
やはり会話はこんなふうに、キャッチボールを楽しみたいですよね。

![会話のキャッチボール](app/static/day22_02.png "会話のキャッチボール")

22日目では過去の会話履歴も踏まえた会話ができるようにアプリを改良していきましょう。

## セッションステートを使う
チャットアプリで会話を続けられるようにするには、過去の会話の履歴をセッションステートに保存し、新しいメッセージに加えて過去のメッセージも一緒に送信することで実現できます。

セッションステートについては[15日目](/?day=15)で詳しく解説していますので、そちらを参照してください。

## 今回のコード
今回のコードはこちらです。
```
import json

import streamlit as st
from snowflake.cortex import Complete
from snowflake.snowpark.context import get_active_session


def extract_message_from_response(response: str) -> str:
    # JSON文字列を辞書に変換
    response_dict = json.loads(response)
    
    # choices 配列からメッセージを取得
    return response_dict["choices"][0]["messages"]


# Get the current credentials
session = get_active_session()

# LLMモデルの選択肢
LLM_OPTIONS = [
    "mistral-large2",
    "llama3.1-8b",
    "llama3.1-70b",
]

# LLMモデルの選択
llm_model = st.selectbox("対話するCortex LLMモデルを選択してください", LLM_OPTIONS)


# 会話履歴をセッション状態で保持
if "messages" not in st.session_state:
    st.session_state.messages = []

# 過去の会話を表示
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 新しいプロンプトを送信
if prompt := st.chat_input("Cortex LLMとのチャットを始めましょう"):
    # ユーザーのメッセージを追加
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # LLMに履歴を含むリクエストを送信
    response_dict = Complete(llm_model, st.session_state.messages)
    response = extract_message_from_response(response_dict)
    
    # アシスタントのレスポンスを追加
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)

```

昨日と同じくパッケージで `Snowflake-ml-python` を追加してからRunを押しましょう。

![snowflake-ml-python](app/static/day22_01.png "snowflake-ml-pythonを忘れずに追加")

それでは21日目からの変更点を見ていきましょう。

## 会話履歴を保存するセッションステートを定義する
まずは会話履歴を保存するセッションステートを定義します。  
30-32行目の以下の部分です。  
```
# 会話履歴をセッション状態で保持
if "messages" not in st.session_state:
    st.session_state.messages = []

```

## 新しいプロンプトの送信時に過去のメッセージを追加する
新しいプロンプトを送信する際には、過去のメッセージをすべて追加（append）してComplete関数に渡します。   
39-48行目の以下の部分です。
```
# 新しいプロンプトを送信
if prompt := st.chat_input("Cortex LLMとのチャットを始めましょう"):
    # ユーザーのメッセージを追加
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # LLMに履歴を含むリクエストを送信
    response_dict = Complete(llm_model, st.session_state.messages)
    response = extract_message_from_response(response_dict)

```

このコードの中で実行されている関数 `extract_message_from_response()` は8-13行目で定義されている以下の関数です。
```
def extract_message_from_response(response: str) -> str:
    # JSON文字列を辞書に変換
    response_dict = json.loads(response)
    
    # choices 配列からメッセージを取得
    return response_dict["choices"][0]["messages"]
```
この関数ではComplete関数で受け取ったJSON形式のresponseからメッセージ部分を抽出しています。
この時受け取っているresponseは以下のようなデータになっています。

```
{
  "choices": {
    "0": {
      "messages": "もちろんです！プリキュアシリーズの良さを3つ挙げると以下のような点があります（以下略"
    }
  },
  "created": 1734576442,
  "model": "mistral-large2",
  "usage": {
    "completion_tokens": 453,
    "prompt_tokens": 26,
    "total_tokens": 479
  }
}
```

## レスポンスを受け取ったら会話履歴に追加する
上記に続く処理の後に、レスポンスを会話履歴のセッションステートに追加します。  
50-53行目の以下の部分です。
```
    # アシスタントのレスポンスを追加
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
```

## すべての会話履歴を表示する
新しいレスポンスが追加されたら、改めて先頭から再実行されたコードの30-32行目の部分でこれまでのすべての会話履歴を表示します。
```
# 過去の会話を表示
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
```

## 22日目のまとめ
本日はセッションステートを活用して過去の履歴を踏まえた会話ができるようにアプリをパワーアップさせることに成功しました。

これで本日の内容は完了です。  
楽しい会話のキャッチボールをお楽しみください！